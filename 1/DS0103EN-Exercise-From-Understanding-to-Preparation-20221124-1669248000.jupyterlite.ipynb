{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%203/images/IDSNlogo.png\" width=\"400\"> </a>\n",
    "\n",
    "# From Understanding to Preparation\n",
    "\n",
    "Estimated time needed: **20** minutes\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   Understand Data \n",
    "-   Prepare Data for analysis and inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, we will continue learning about the data science methodology, and focus on the **Data Understanding** and the **Data Preparation** stages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 10px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#Recap\">Recap</a></li>\n",
    "        <li><a href=\"#Data-Understanding\">Data Understanding</a></li>\n",
    "        <li><a href=\"#Data-Preparation\">Data Preparation</a></li>\n",
    "     </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Recap\">\n",
    "<h2>Recap</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab **From Requirements to Collection**, we learned that the data we need to answer the question developed in the business understanding stage, namely \"_can we automate the process of determining the cuisine of a given recipe?_\", is readily available. A researcher named Yong-Yeol Ahn scraped tens of thousands of food recipes (cuisines and ingredients) from three different websites, namely:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig3_allrecipes.png\" width=\"550\">\n",
    "    <br>\n",
    "    <div>www.allrecipes.com</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig4_epicurious.png\" width=\"550\">\n",
    "    <br>\n",
    "    <div>www.epicurious.com</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig5_menupan.png\" width=\"550\">\n",
    "    <br>\n",
    "    <div>www.menupan.com</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on Yong-Yeol Ahn and his research, you can read his paper on [Flavor Network and the Principles of Food Pairing](http://yongyeol.com/papers/ahn-flavornet-2011.pdf?utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork-20083987).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also collected the data and placed it on an IBM server for your convenience.\n",
    "\n",
    "* * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Data Understanding\">\n",
    "<h2>Data Understanding</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%203/images/flowchart_data_understanding.png\" width=\"600\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Important note:</strong> Please note that you are not expected to know how to program in python. The following code is meant to illustrate the stage of data collection, so it is totally fine if you do not understand the individual lines of code. There will be a full course in this certificate on programming in python, i.e.,Python for Data Science, which will teach you how to program in Python if you decide to complete this certificate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this notebook:\n",
    "\n",
    "To run any of the following cells of code, you can type **Shift + Enter** to excute the code in a cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the version of Python installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Python version if running locally\n",
    "# !python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the library and dependencies that we will need to run this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Practices import pandasornekleri as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np # import numpy library\n",
    "import re # import library for regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from the IBM server and read it into a _pandas_ dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Uncomment if running locally, else download data using the following code cell\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m recipes \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m202/recipes.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData read into dataframe!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1881\u001B[0m     f,\n\u001B[1;32m   1882\u001B[0m     mode,\n\u001B[1;32m   1883\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1884\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1885\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1886\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1887\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1888\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1889\u001B[0m )\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:728\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    725\u001B[0m     codecs\u001B[38;5;241m.\u001B[39mlookup_error(errors)\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# open URLs\u001B[39;00m\n\u001B[0;32m--> 728\u001B[0m ioargs \u001B[38;5;241m=\u001B[39m _get_filepath_or_buffer(\n\u001B[1;32m    729\u001B[0m     path_or_buf,\n\u001B[1;32m    730\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m    731\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[1;32m    732\u001B[0m     mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    733\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[1;32m    734\u001B[0m )\n\u001B[1;32m    736\u001B[0m handle \u001B[38;5;241m=\u001B[39m ioargs\u001B[38;5;241m.\u001B[39mfilepath_or_buffer\n\u001B[1;32m    737\u001B[0m handles: \u001B[38;5;28mlist\u001B[39m[BaseBuffer]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:389\u001B[0m, in \u001B[0;36m_get_filepath_or_buffer\u001B[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m content_encoding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    387\u001B[0m             \u001B[38;5;66;03m# Override compression based on Content-Encoding header\u001B[39;00m\n\u001B[1;32m    388\u001B[0m             compression \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmethod\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m--> 389\u001B[0m         reader \u001B[38;5;241m=\u001B[39m BytesIO(req\u001B[38;5;241m.\u001B[39mread())\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m IOArgs(\n\u001B[1;32m    391\u001B[0m         filepath_or_buffer\u001B[38;5;241m=\u001B[39mreader,\n\u001B[1;32m    392\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    395\u001B[0m         mode\u001B[38;5;241m=\u001B[39mfsspec_mode,\n\u001B[1;32m    396\u001B[0m     )\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/http/client.py:495\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    494\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 495\u001B[0m         s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_safe_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength)\n\u001B[1;32m    496\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m IncompleteRead:\n\u001B[1;32m    497\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/http/client.py:642\u001B[0m, in \u001B[0;36mHTTPResponse._safe_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_safe_read\u001B[39m(\u001B[38;5;28mself\u001B[39m, amt):\n\u001B[1;32m    636\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Read the number of bytes requested.\u001B[39;00m\n\u001B[1;32m    637\u001B[0m \n\u001B[1;32m    638\u001B[0m \u001B[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001B[39;00m\n\u001B[1;32m    639\u001B[0m \u001B[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001B[39;00m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001B[39;00m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 642\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m<\u001B[39m amt:\n\u001B[1;32m    644\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m IncompleteRead(data, amt\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(data))\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/socket.py:719\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    717\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot read from timed out object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    718\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 719\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[1;32m    720\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    721\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1304\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1300\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1301\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1302\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1303\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1138\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1137\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1138\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1139\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1140\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Uncomment if running locally, else download data using the following code cell\n",
    "recipes = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv\")\n",
    "\n",
    "print(\"Data read into dataframe!\") # takes about 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'js'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mjs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m fetch\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mio\u001B[39;00m \n\u001B[1;32m      4\u001B[0m URL \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m202/recipes.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'js'"
     ]
    }
   ],
   "source": [
    "from js import fetch\n",
    "import io \n",
    "\n",
    "URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv'\n",
    "resp = await fetch(URL)\n",
    "text = io.BytesIO((await resp.arrayBuffer()).to_py())\n",
    "\n",
    "recipes =  pd.read_csv(text)\n",
    "\n",
    " \n",
    "\n",
    "print('Data read into dataframe!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dimensions of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our dataset consists of 57,691 recipes. Each row represents a recipe, and for each recipe, the corresponding cuisine is documented as well as whether 384 ingredients exist in the recipe or not, beginning with almond and ending with zucchini.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that a basic sushi recipe includes the ingredients:\n",
    "\n",
    "-   rice\n",
    "-   soy sauce\n",
    "-   wasabi\n",
    "-   some fish/vegetables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that these ingredients exist in our dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = list(recipes.columns.values)\n",
    "\n",
    "print([match.group(0) for ingredient in ingredients for match in [(re.compile(\".*(rice).*\")).search(ingredient)] if match])\n",
    "print([match.group(0) for ingredient in ingredients for match in [(re.compile(\".*(wasabi).*\")).search(ingredient)] if match])\n",
    "print([match.group(0) for ingredient in ingredients for match in [(re.compile(\".*(soy).*\")).search(ingredient)] if match])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, they do!\n",
    "\n",
    "-   rice exists as rice.\n",
    "-   wasabi exists as wasabi.\n",
    "-   soy exists as soy_sauce.\n",
    "\n",
    "So maybe if a recipe contains all three ingredients: rice, wasabi, and soy_sauce, then we can confidently say that the recipe is a **Japanese** cuisine! Let's keep this in mind!\n",
    "\n",
    "* * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Data Preparation\">\n",
    "<h2>Data Preparation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%203/images/lab3_fig5_flowchart_data_preparation.png\" width=\"600\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will prepare data for the next stage in the data science methodology, which is modeling. This stage involves exploring the data further and making sure that it is in the right format for the machine learning algorithm that we selected in the analytic approach stage, which is decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, look at the data to see if it needs cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes[\"country\"].value_counts() # frequency table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the above table, we can make the following observations:\n",
    "\n",
    "1.  Cuisine column is labeled as Country, which is inaccurate.\n",
    "2.  Cuisine names are not consistent as not all of them start with an uppercase first letter.\n",
    "3.  Some cuisines are duplicated as variation of the country name, such as Vietnam and Vietnamese.\n",
    "4.  Some cuisines have very few recipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fix these problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the name of the column showing the cuisine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = recipes.columns.values\n",
    "column_names[0] = \"cuisine\"\n",
    "recipes.columns = column_names\n",
    "\n",
    "recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all the cuisine names lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes[\"cuisine\"] = recipes[\"cuisine\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the cuisine names consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.loc[recipes[\"cuisine\"] == \"austria\", \"cuisine\"] = \"austrian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"belgium\", \"cuisine\"] = \"belgian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"china\", \"cuisine\"] = \"chinese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"canada\", \"cuisine\"] = \"canadian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"netherlands\", \"cuisine\"] = \"dutch\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"france\", \"cuisine\"] = \"french\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"germany\", \"cuisine\"] = \"german\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"india\", \"cuisine\"] = \"indian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"indonesia\", \"cuisine\"] = \"indonesian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"iran\", \"cuisine\"] = \"iranian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"italy\", \"cuisine\"] = \"italian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"japan\", \"cuisine\"] = \"japanese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"israel\", \"cuisine\"] = \"israeli\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"korea\", \"cuisine\"] = \"korean\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"lebanon\", \"cuisine\"] = \"lebanese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"malaysia\", \"cuisine\"] = \"malaysian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"mexico\", \"cuisine\"] = \"mexican\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"pakistan\", \"cuisine\"] = \"pakistani\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"philippines\", \"cuisine\"] = \"philippine\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"scandinavia\", \"cuisine\"] = \"scandinavian\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"spain\", \"cuisine\"] = \"spanish_portuguese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"portugal\", \"cuisine\"] = \"spanish_portuguese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"switzerland\", \"cuisine\"] = \"swiss\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"thailand\", \"cuisine\"] = \"thai\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"turkey\", \"cuisine\"] = \"turkish\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"vietnam\", \"cuisine\"] = \"vietnamese\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"uk-and-ireland\", \"cuisine\"] = \"uk-and-irish\"\n",
    "recipes.loc[recipes[\"cuisine\"] == \"irish\", \"cuisine\"] = \"uk-and-irish\"\n",
    "\n",
    "recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cuisines with < 50 recipes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of cuisines to keep\n",
    "recipes_counts = recipes[\"cuisine\"].value_counts()\n",
    "cuisines_indices = recipes_counts > 50\n",
    "\n",
    "cuisines_to_keep = list(np.array(recipes_counts.index.values)[np.array(cuisines_indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = recipes.shape[0] # number of rows of original dataframe\n",
    "print(\"Number of rows of original dataframe is {}.\".format(rows_before))\n",
    "\n",
    "recipes = recipes.loc[recipes['cuisine'].isin(cuisines_to_keep)]\n",
    "\n",
    "rows_after = recipes.shape[0] # number of rows of processed dataframe\n",
    "print(\"Number of rows of processed dataframe is {}.\".format(rows_after))\n",
    "\n",
    "print(\"{} rows removed!\".format(rows_before - rows_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all Yes's to 1's and the No's to 0's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes.replace(to_replace=\"Yes\", value=1)\n",
    "recipes = recipes.replace(to_replace=\"No\", value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's analyze the data a little more in order to learn the data better and note any interesting preliminary observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get the recipes that contain **rice** _and_ **soy** _and_ **wasabi** _and_ **seaweed**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_recipes = recipes.loc[\n",
    "    (recipes[\"rice\"] == 1) &\n",
    "    (recipes[\"soy_sauce\"] == 1) &\n",
    "    (recipes[\"wasabi\"] == 1) &\n",
    "    (recipes[\"seaweed\"] == 1)\n",
    "]\n",
    "\n",
    "check_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the above code, can we classify all recipes that contain **rice** _and_ **soy** _and_ **wasabi** _and_ **seaweed** as **Japanese** recipes? Why?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a solution</summary>\n",
    "\n",
    "```python\n",
    "   #The correct answer is:\n",
    "    \n",
    "    No, because other recipes such as Asian and East_Asian recipes also contain these ingredients.\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the ingredients across all recipes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum each column\n",
    "ing = recipes.iloc[:, 1:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define each column as a pandas series\n",
    "ingredient = pd.Series(ing.index.values, index = np.arange(len(ing)))\n",
    "count = pd.Series(list(ing), index = np.arange(len(ing)))\n",
    "\n",
    "# create the dataframe\n",
    "ing_df = pd.DataFrame(dict(ingredient = ingredient, count = count))\n",
    "ing_df = ing_df[[\"ingredient\", \"count\"]]\n",
    "print(ing_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe of ingredients and their total counts across all recipes. Let's sort this dataframe in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_df.sort_values([\"count\"], ascending=False, inplace=True)\n",
    "ing_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(ing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the 3 most popular ingredients?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your Answer:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a solution</summary>\n",
    "\n",
    "```python\n",
    "   #1. Egg with <strong>21,025</strong> occurrences. \n",
    "# 2. Wheat with <strong>20,781</strong> occurrences. \n",
    "# 3. Butter with <strong>20,719</strong> occurrences.\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that there is a problem with the above table. There are ~40,000 American recipes in our dataset, which means that the data is biased towards American ingredients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore**, let's compute a more objective summary of the ingredients by looking at the ingredients per cuisine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a _profile_ for each cuisine.\n",
    "\n",
    "In other words, let's try to find out what ingredients Chinese people typically use, and what is **Canadian** food for example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = recipes.groupby(\"cuisine\").mean()\n",
    "cuisines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have just created a dataframe where each row is a cuisine and each column (except for the first column) is an ingredient, and the row values represent the percentage of each ingredient in the corresponding cuisine.\n",
    "\n",
    "**For example**:\n",
    "\n",
    "-   _almond_ is present across 15.65% of all of the **African** recipes.\n",
    "-   _butter_ is present across 38.11% of all of the **Canadian** recipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the profile for each cuisine by displaying the top four ingredients in each cuisine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ingredients = 4 # define number of top ingredients to print\n",
    "\n",
    "# define a function that prints the top ingredients for each cuisine\n",
    "def print_top_ingredients(row):\n",
    "    print(row.name.upper())\n",
    "    row_sorted = row.sort_values(ascending=False)*100\n",
    "    top_ingredients = list(row_sorted.index.values)[0:num_ingredients]\n",
    "    row_sorted = list(row_sorted)[0:num_ingredients]\n",
    "\n",
    "    for ind, ingredient in enumerate(top_ingredients):\n",
    "        print(\"%s (%d%%)\" % (ingredient, row_sorted[ind]), end=' ')\n",
    "    print(\"\\n\")\n",
    "\n",
    "# apply function to cuisines dataframe\n",
    "create_cuisines_profiles = cuisines.apply(print_top_ingredients, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we feel that we have understood the data well and the data is ready and is in the right format for modeling!\n",
    "\n",
    "* * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/aklson/\" target=\"_blank\">Alex Aklson</a>\n",
    "\n",
    "<!--\n",
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n",
    "| ----------------- | ------- | ---------- | ---------------------------------- |\n",
    "| 2021-04-06        | 2.2     | Malika     | Updated dataset link               |\n",
    "| 2020-09-23        | 2.1     | Lakshmi    | Fixed Typo errors                  |\n",
    "| 2020-08-27        | 2.0     | Lavanya    | Moved lab to course repo in GitLab |\n",
    "-->\n",
    "<hr>\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/3mTotNF1T0WIegD0OwqrzA/footerLatest.png\" width=\"1300\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "prev_pub_hash": "bd7973bf9f119b1670515cb9f87c7221d080b994c6fdf2a8955ad7526be84463"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
